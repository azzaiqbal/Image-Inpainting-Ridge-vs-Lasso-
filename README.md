# Image-Inpainting-Ridge-vs-Lasso-Algorithms

Image Inpainting is the process of reconstructing missing regions in an image. It is an important problem in computer vision and an essential functionality in many imaging and graphics applications, e.g. object removal, image/video restoration, manipulation, re-targeting, compositing, and image-based rendering. Further applications include text/object removal, texture synthesis, and transmission error concealment. In this process, we essentially start with a corrupted or masked input image and define which pixels are missing or invalid that need to be filled, and also the remaining pixels as the truth or valid pixels that would be used to help fill in the missing pixels. 

This form of representation is defined as sparse representation which assumes that signals can be described as a linear combination of a few atoms from a predefined dictionary. In this application, it assumes that what was described earlier: missing pixels in an image can be defined by the pre-existing ones for image inpainting and reconstruction. This assumption is a suitable one to make because natural images existing all around us have a lot of redundancy and can be represented by a smaller set of basic vectors. Since in sparse representation, most entries are simply zero, we only have to store the non-zero elements, which leads to more memory and computation efficiency.

The core idea behind tackling this problem is to first search for the most similar image ‘patches’ from the existing pixels from the image itself (or other images within the dataset) and directly paste the patches onto the missing parts. This kind of primitive search algorithm can be very inefficient and time consuming, so several deep learning approaches have been developed to improve on this basic idea.

The approaches are based on convolutional neural deep learning networks which use different loss functions to guide the algorithm towards the optimal solution. The loss functions can include L1 based, L2 based, Adversarial loss, texture loss, as well as combinations of several loss functions. The paper which we explore uses L1 regularization in images with sparse representations. L1 was used in this case because this regularization method penalizes high signals in a way that they will be set to zero, and that entire feature is removed from the model.  That leads to the resulting signal having a large number of 0 entries. This does not happen with L2 regularization as it penalizes 〖weight〗^2, and the derivative is 2 * weight, while in L1, it penalizes |weight| and the derivative is a constant whose value is independent of weight. Thus, in L2, it removes a percentage of the weight every time, but never actually gets to 0 [7]. Therefore, it is understandable why L1 was used in sparse representations of image inpainting to encourage 0 values. However, this is a very computationally expensive operation, so other regularization methods should be explored, such as the L2 regularization, or Ridge algorithm.

